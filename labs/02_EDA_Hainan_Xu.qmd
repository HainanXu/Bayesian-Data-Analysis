---
title: "Lab 2 Toronto TTC delay and Mayor Contribution Analyses"
author: Hainan Xu
format: pdf
editor: visual
---

```{r message=FALSE}
library(opendatatoronto)
library(tidyverse)
library(stringr)
library(skimr) # EDA
library(visdat) # EDA
library(janitor)
library(lubridate)
library(ggrepel)
```

We import the data that is preprocessed in the lab2:

```{r message=FALSE}
delay_2022 <- read_csv("labs/ttcdelay_2022.csv")
```

**1. Using the `delay_2022` data, plot the five stations with the highest mean delays. Facet the graph by `line`** .

The station variable does not always suggest only one station, it might also suggest the route between one station to another, that could be one of the reasons why some of the delays are really long.

```{r}
delay_2022 |>
  group_by(station,line) |>
  summarize(mean_delay=mean(min_delay))|>#,.groups = 'drop'
  arrange(-mean_delay)|>
  head(5)|>
  ggplot(aes(station, mean_delay, fill = line)) + 
  geom_col() + 
  facet_wrap(vars(line),  # Facet by the 'line' variable
             scales = "free_y",
             nrow = 4) +
  coord_flip()+
  labs(title = "Top 5 Stations with the Highest Delays",x="Station",y="Mean Delay ( in minutes)")+
  theme_bw()
  
```

**2. Restrict the `delay_2022` to delays that are greater than 0 and to only have delay reasons that appear in the top 50% of most frequent delay reasons. Perform a regression to study the association between delay minutes, and two covariates: line and delay reason. It's up to you how to specify the model, but make sure it's appropriate to the data types. Comment briefly on the results, including whether results generally agree with the exploratory data analysis above.**

Below are the top 5 most frequent delay reasons. 

```{r}
#top 50% of most frequent delay reasons

delay_2022|> 
  group_by(code_red)|> 
  summarise(frequency=n()) |> 
  arrange(-frequency) |> 
  mutate(rank=cumsum(frequency)/sum(frequency)) |>
  slice(1:5)
```

Since the min_delay variable is continuous, we fit a linear regression:

```{r}
top_delay_reasons<- delay_2022|> 
  group_by(code_red)|> 
  summarise(frequency=n(),na.rm=TRUE) |> 
  arrange(-frequency) |> 
  mutate(rank=cumsum(frequency)/sum(frequency)) |> 
  filter(rank<= 0.5) |> 
  select(code_red)


#filter delay_2022
q2<-delay_2022|>filter(min_delay>0 , code_red %in% top_delay_reasons$code_red)
#fit the model
model<-lm(min_delay~line + code_red, data=q2)
summary(model)
```

From the output above, with baseline lineBD and code being disorderly, the average estimated late time is around 6.7 minutes. If the line is SRT, the average estimated delay time will increase by 6.78 minutes. This does noe match what we observed in previos EDA, where we found the top 5 delayed stations are either lineYU or lineBD. The model is poorly fitted. More covariates need to be incorporated into this model, and we may need to consider performing some transformations or other analyses methods.

3.  **Using the** `opendatatoronto` **package, download the data on mayoral campaign contributions for 2014 and clean it up**.

```{r message=FALSE}
all_data <- search_packages("campaign")
campaign_data_ids <- all_data$id
resources <- list_package_resources(campaign_data_ids[1])
mayor_campaign_data <- get_resource('8b42906f-c894-4e93-a98e-acac200f34a4')
mayor_contributions <- mayor_campaign_data$`2_Mayor_Contributions_2014_election.xls`
colnames(mayor_contributions) <- as.character(mayor_contributions[1, ])
mayor_contributions <- mayor_contributions[-1, ]
rownames(mayor_contributions) <- NULL
clean_mayor_contributions <- mayor_contributions |>
  clean_names()
head(clean_mayor_contributions )
```

4.**Summarize the variables in the dataset. Are there missing values, and if so, should we be worried about them? Is every variable in the format it should be? If not, create new variable(s) that are in the right format**.

The data are being summarized as the output as follows. There are missing values in the data in `contributors_address`, `goods_or_service_desc`,`relationship_to_candidate`,`president_business_manager`,and `authorized_representative` and `ward`. however, we may not need to worry about them since over 99% of the data of those vatiables are missing, and we will not analyse those variables. Based on the output, all the variables are characters. We modified the `contribution_amount` to be numeric.

```{r}
skim(clean_mayor_contributions)
data<- clean_mayor_contributions|> mutate(contribution_amount=as.numeric(contribution_amount))
```

5.  **Visually explore the distribution of values of the contributions. What contributions are notable outliers? Do they share a similar characteristic(s)? It may be useful to plot the distribution of contributions without these outliers to get a better sense of the majority of the data.**

We plot the histogram of contribution amount with log10 transformed x-axis. We observe that there are some large contributions.

```{r}
#histogram
ggplot(data=data)+
 geom_histogram(aes(x=contribution_amount))+
 scale_x_log10()+theme_bw()
```

We plot the boxplot and get the outliers. The contributions over 1100 are considered as outliers for the boxplot. The threshold is calculated by 75% quantile of the data \* 1.5 IQR.

```{r}
quantile(data$contribution_amount,0.75)+1.5*IQR(data$contribution_amount)
```

Some notable outliers are :2210.00 ,20000.00, 23623.63, 50000.00, 78804.80 and 508224.73. The contributors of the contributions that are over \$4000 are contributed by the candidates themselves.

```{r}
data|> filter(contribution_amount>=1100) |> arrange(-contribution_amount) |> select(contributors_name,candidate,contribution_amount)

#data|> filter(contribution_amount>=1100) |> arrange(-contribution_amount) |> select(contributors_name,candidate,contribution_amount) |> group_by(candidate) |> summarise(frequency=n()) |> arrange(-frequency)

```

We only plot the values that are smaller or equal to 1100 to get a better sense of the data.

```{r}
filtered_data <-data |> filter(contribution_amount <= 1100)
library(gridExtra)
a<-ggplot(data=filtered_data)+
   geom_boxplot(aes(x=contribution_amount))+
   theme_bw()+labs(title="Boxplot of Contribution Amounts")
b<-ggplot(filtered_data) + geom_histogram(aes(x=contribution_amount),bins = 25) +theme_bw() + labs(title="Histogram of Contribution Amounts", xlab= "contribution amount")

grid.arrange(a, b, ncol = 1)
```

6.  List the top five candidates in each of these categories:
    -   total contributions
    -   mean contribution
    -   number of contributions

```{r}
#top5 total contributions
total_contributions<- data |> group_by(candidate) |> summarise(total_contributions=sum(contribution_amount)) |> arrange(-total_contributions) |> slice(1:5)
total_contributions
#top5 mean contributions
mean_contributions<- data|> group_by(candidate)|>
  summarise(mean_contributions=mean(contribution_amount)) |> arrange(-mean_contributions) |> slice(1:5)
mean_contributions
#top5 number of countributions
number_of_contributions<-data|> group_by(candidate)|>
  summarise(frequency=n()) |>
  arrange(-frequency)|>
  slice(1:5)
number_of_contributions
```

7.  Repeat 6 but without contributions from the candidates themselves.

```{r}
#remove the contributions from the candidates themselves
data2<- data |> filter(contributors_name!=candidate)

#top5 total contributions
total_contributions<- data2 |> group_by(candidate) |> summarise(total_contributions=sum(contribution_amount)) |> arrange(-total_contributions) |> slice(1:5)
total_contributions
#top5 mean contributions
mean_contributions<- data2|> group_by(candidate)|>
  summarise(mean_contributions=mean(contribution_amount)) |> arrange(-mean_contributions) |> slice(1:5)
mean_contributions
#top5 number of countributions
number_of_contributions<-data2|> group_by(candidate)|>
  summarise(frequency=n()) |>
  arrange(-frequency)|>
  slice(1:5)
number_of_contributions
```

8.  **How many contributors gave money to more than one candidate?**

There are 184 contributors gave money to more than one candidate.

```{r}
data|> group_by(contributors_name) |> summarise(num_contribution=n_distinct(candidate)) |> filter(num_contribution>1) |> nrow()
```
